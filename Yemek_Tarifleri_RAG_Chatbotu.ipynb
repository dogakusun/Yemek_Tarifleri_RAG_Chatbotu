{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObqMXddccMDaMbbh2kQJE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dogakusun/Yemek_Tarifleri_RAG_Chatbotu/blob/main/Yemek_Tarifleri_RAG_Chatbotu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8plGs0xdCcXI"
      },
      "outputs": [],
      "source": [
        "# Gerekli kÃ¼tÃ¼phaneleri kurma\n",
        "!pip install -q google-genai langchain langchain-community chromadb streamlit datasets pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga3mj8YcSCoW",
        "outputId": "4100a494-fd25-4487-fd10-837653c7a7aa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (3.0.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.12.3)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.26.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.41.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (6.33.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.4.37)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.32.5)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (6.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Colab'den GEMINI_API_KEY'i al ve ortam deÄŸiÅŸkeni olarak ayarla\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "print(\"Ortam HazÄ±rlÄ±ÄŸÄ± TamamlandÄ±. API AnahtarÄ± YÃ¼klendi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vftF4OGDg7G",
        "outputId": "ee146d8e-2b26-46e9-f68b-8efc2667fde5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ortam HazÄ±rlÄ±ÄŸÄ± TamamlandÄ±. API AnahtarÄ± YÃ¼klendi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 2.1. Veri Setini YÃ¼kleme ve YapÄ±landÄ±rma (TEMÄ°ZLEME EKLENDÄ°)\n",
        "# -----------------------------------------------------------\n",
        "from datasets import load_dataset\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "print(\"Veri Seti YÃ¼kleniyor ve Temizleniyor...\")\n",
        "\n",
        "dataset = load_dataset(\"mertbozkurt/llama2-TR-recipe\", split=\"train\")\n",
        "recipes = dataset.select(range(5000))\n",
        "\n",
        "langchain_docs = []\n",
        "for i, item in enumerate(recipes):\n",
        "    recipe_text = item.get('text', \"\")\n",
        "\n",
        "    if not recipe_text:\n",
        "         continue\n",
        "\n",
        "    # KRÄ°TÄ°K TEMÄ°ZLEME ADIMI: Etiketleri kaldÄ±rÄ±yoruz\n",
        "    recipe_text = recipe_text.replace(\"<s>[INST]\", \"SORU:\").replace(\"[/INST] \", \"CEVAP:\").replace(\"</s>\", \"\")\n",
        "\n",
        "    doc = Document(\n",
        "        page_content=recipe_text,\n",
        "        metadata={\"source\": \"HuggingFace Recipe Dataset\", \"recipe_id\": i}\n",
        "    )\n",
        "    langchain_docs.append(doc)\n",
        "\n",
        "print(f\"Toplam {len(langchain_docs)} adet tarif belgesi temizlenerek oluÅŸturuldu.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaC28M9dCqZw",
        "outputId": "e439bee0-44b7-4e2d-915d-9871f9b742de"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Veri Seti YÃ¼kleniyor ve Temizleniyor...\n",
            "Toplam 5000 adet tarif belgesi temizlenerek oluÅŸturuldu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 2.2. Metin ParÃ§alama\n",
        "# -----------------------------------------------------------\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Bu kodun altÄ±ndaki 2.2 Metin ParÃ§alama kodunu aynen tekrar Ã§alÄ±ÅŸtÄ±rÄ±n.\n",
        "# (chunks listesini yeni, temizlenmiÅŸ verilerle yeniden doldurmak iÃ§in)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=4000,\n",
        "    chunk_overlap=200,\n",
        ")\n",
        "chunks = text_splitter.split_documents(langchain_docs)\n",
        "print(f\"ParÃ§alama tamamlandÄ±: {len(chunks)} adet parÃ§a.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yWJAv_oZ4-V",
        "outputId": "e7b407a2-bb0d-4ba7-e2b9-b793bca5c800"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ParÃ§alama tamamlandÄ±: 5000 adet parÃ§a.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 2.3. Embedding ve ChromaDB OluÅŸturma\n",
        "# -----------------------------------------------------------\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"Embedding ve VektÃ¶r VeritabanÄ± (ChromaDB) OluÅŸturuluyor... Bu adÄ±m zaman alabilir.\")\n",
        "\n",
        "# API AnahtarÄ±nÄ± doÄŸrudan Colab Gizli AnahtarlarÄ±ndan Ã§ekme\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# Google'Ä±n text-embedding-004 modelini kullanma\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"text-embedding-004\",\n",
        "    google_api_key=GEMINI_API_KEY\n",
        ")\n",
        "\n",
        "# VeritabanÄ±nÄ± Colab ortamÄ±nda kalÄ±cÄ± bir klasÃ¶re kaydetme.\n",
        "persist_dir = \"./chroma_db_tarifler\"\n",
        "\n",
        "# ChromaDB'yi oluÅŸtur ve verileri gÃ¶merek kaydetme\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_dir\n",
        ")\n",
        "\n",
        "# ArayÃ¼z iÃ§in bir retriever (geri Ã§aÄŸÄ±rÄ±cÄ±) hazÄ±rla\n",
        "# k=6 olarak yÃ¼kseltildi: En alakalÄ± 6 metin parÃ§asÄ±nÄ± Ã§ekecek\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"ChromaDB baÅŸarÄ±yla oluÅŸturuldu ve '{persist_dir}' dizinine kaydedildi.\")\n",
        "print(\"Retriever k=6 olarak gÃ¼ncellendi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQeqH6Y4KJ1_",
        "outputId": "30b9074c-69a8-4bb0-d9e4-05f7c00c97f7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding ve VektÃ¶r VeritabanÄ± (ChromaDB) OluÅŸturuluyor... Bu adÄ±m zaman alabilir.\n",
            "--------------------------------------------------\n",
            "ChromaDB baÅŸarÄ±yla oluÅŸturuldu ve './chroma_db_tarifler' dizinine kaydedildi.\n",
            "Retriever k=6 olarak gÃ¼ncellendi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 3.1. LangChain RAG Zincirini Kurma\n",
        "# -----------------------------------------------------------\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"RAG Zinciri BileÅŸenleri TanÄ±mlanÄ±yor...\")\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# 1. LLM'i TanÄ±mlama: SÄ°STEM TALÄ°MATI EKLENDÄ° ve TEMPERATURE 0.0\n",
        "# LLM'i, prompt yerine doÄŸrudan model seviyesinde yÃ¶nlendiriyoruz.\n",
        "system_prompt_instruction = (\n",
        "    \"Sen, yalnÄ±zca sana saÄŸlanan BAÄžLAM (Context) Ã¼zerinden cevap veren, TÃ¼rk mutfaÄŸÄ±na Ã¶zel bir asistansÄ±n. \"\n",
        "    \"BaÄŸlamda bilgi varsa, bu bilgiyi KESÄ°NLÄ°KLE kullanmak ve cevap Ã¼retmek zorundasÄ±n. Cevap formatÄ± sadece Yemek AdÄ±, Malzemeler, Tarif/YapÄ±lÄ±ÅŸÄ± olmalÄ±dÄ±r. \"\n",
        "    \"EÄŸer baÄŸlamda cevap verecek hiÃ§bir bilgi yoksa, sadece ÅŸu cÃ¼mleyi kullan: 'ÃœzgÃ¼nÃ¼m, aradÄ±ÄŸÄ±nÄ±z tarifi ÅŸu anda veri tabanÄ±mda bulamÄ±yorum. Belki baÅŸka bir yemek tarifi sormak istersiniz?'\"\n",
        ")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.0,\n",
        "    google_api_key=GEMINI_API_KEY,\n",
        "    # SÄ°STEM TALÄ°MATINI DOÄžRUDAN MODEL SEVÄ°YESÄ°NDE GÃ–NDERÄ°YORUZ\n",
        "    model_kwargs={\"system_instruction\": system_prompt_instruction}\n",
        ")\n",
        "\n",
        "# 2. Prompt Åžablonu (ArtÄ±k LLM yÃ¶nlendirildiÄŸi iÃ§in bu prompt SADECE formatÄ± verecek)\n",
        "RAG_PROMPT = \"\"\"\n",
        "AÅŸaÄŸÄ±daki BAÄžLAM'Ä± kullanarak SORU'ya cevap ver. CevabÄ±nÄ± **Yemek AdÄ±**, **Malzemeler** ve **YapÄ±lÄ±ÅŸÄ±** baÅŸlÄ±klarÄ± altÄ±nda dÃ¼zenle.\n",
        "\n",
        "BAÄžLAM:\n",
        "{context}\n",
        "\n",
        "SORU:\n",
        "{question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(RAG_PROMPT)\n",
        "\n",
        "# 3. RAG Zincirini BirleÅŸtirme\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"RAG Zinciri BaÅŸarÄ±yla KURULDU. Sistem TalimatÄ± ile LLM zorunlu yÃ¶nlendirildi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiO01wbEU1UF",
        "outputId": "b16ac047-bf6d-4065-f7a7-5f1d6bc93d88"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG Zinciri BileÅŸenleri TanÄ±mlanÄ±yor...\n",
            "--------------------------------------------------\n",
            "RAG Zinciri BaÅŸarÄ±yla KURULDU. Sistem TalimatÄ± ile LLM zorunlu yÃ¶nlendirildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 3.2. RAG Zincirini Test Etme\n",
        "# -----------------------------------------------------------\n",
        "print(\"RAG Zinciri Test Ediliyor...\")\n",
        "\n",
        "# 1. Test Sorgusu\n",
        "question_1 = \"SodalÄ± KÃ¶fte nasÄ±l yapÄ±lÄ±r?\"\n",
        "print(f\"\\n[TEST 1] SORU: {question_1}\")\n",
        "\n",
        "# rag_chain'i Ã§aÄŸÄ±r\n",
        "response_1 = rag_chain.invoke(question_1)\n",
        "\n",
        "print(\"-\" * 20 + \" CEVAP \" + \"-\" * 20)\n",
        "print(response_1)\n",
        "\n",
        "print(\"\\n\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "# 2. Test Sorgusu (BaÅŸarÄ±sÄ±z olmasÄ± ve reddetmesi beklenen)\n",
        "question_2 = \"Amerikan hot-dog tarifi nedir?\"\n",
        "print(f\"[TEST 2] SORU: {question_2}\")\n",
        "\n",
        "# rag_chain'i Ã§aÄŸÄ±r\n",
        "response_2 = rag_chain.invoke(question_2)\n",
        "\n",
        "print(\"-\" * 20 + \" CEVAP \" + \"-\" * 20)\n",
        "print(response_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1Puy14aVY9q",
        "outputId": "c38ca5c6-e704-4a13-dd74-d576ac231f9e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG Zinciri Test Ediliyor...\n",
            "\n",
            "[TEST 1] SORU: SodalÄ± KÃ¶fte nasÄ±l yapÄ±lÄ±r?\n",
            "-------------------- CEVAP --------------------\n",
            "**Yemek AdÄ±**\n",
            "SodalÄ± KÃ¶fte\n",
            "\n",
            "**Malzemeler**\n",
            "*   500 gr kÄ±yma\n",
            "*   1 adet bÃ¼yÃ¼k boy kuru soÄŸan\n",
            "*   1/2 Ã§ay bardaÄŸÄ± galeta unu\n",
            "*   1 tatlÄ± kaÅŸÄ±ÄŸÄ± tuz\n",
            "*   1 Ã§ay kaÅŸÄ±ÄŸÄ± dolusu kÄ±rmÄ±zÄ± toz biber\n",
            "*   1 Ã§ay kaÅŸÄ±ÄŸÄ± kÄ±rmÄ±zÄ± pul biber\n",
            "*   1 Ã§ay kaÅŸÄ±ÄŸÄ± kimyon\n",
            "*   1/2 Ã§ay kaÅŸÄ±ÄŸÄ± karabiber\n",
            "*   1/2 paket kabartma tozu\n",
            "*   1 Ã§ay bardaÄŸÄ± soda\n",
            "\n",
            "**YapÄ±lÄ±ÅŸÄ±**\n",
            "Verilen baÄŸlamda SodalÄ± KÃ¶fte'nin yapÄ±lÄ±ÅŸÄ±na dair bilgi bulunmamaktadÄ±r, sadece malzemeler listelenmiÅŸtir.\n",
            "\n",
            "\n",
            "==================================================\n",
            "\n",
            "[TEST 2] SORU: Amerikan hot-dog tarifi nedir?\n",
            "-------------------- CEVAP --------------------\n",
            "Verilen BAÄžLAM'da \"Amerikan hot-dog\" tarifi bulunmamaktadÄ±r. Bu nedenle sorunuzu mevcut baÄŸlamÄ± kullanarak yanÄ±tlayamÄ±yorum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 4.1. Streamlit Ä°Ã§in Gerekli Paketi Kurma\n",
        "# -----------------------------------------------------------\n",
        "!pip install -q streamlit-colab"
      ],
      "metadata": {
        "id": "-N3S_pRJVf4Z"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 4.2. `app.py` DosyasÄ±nÄ± OluÅŸturma\n",
        "# -----------------------------------------------------------\n",
        "%%writefile app.py\n",
        "# app.py iÃ§eriÄŸi\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# ==================== 1. BAÄžLANTILARI KURMA FONKSÄ°YONU ====================\n",
        "@st.cache_resource\n",
        "def setup_rag_chain():\n",
        "    \"\"\"RAG zincirini kurar ve API anahtarÄ±nÄ± yÃ¶netir.\"\"\"\n",
        "\n",
        "    # 1. API AnahtarÄ±nÄ± Ortam DeÄŸiÅŸkeninden Ã‡ek\n",
        "    # AnahtarÄ±n notebook ortamÄ±nda os.environ'a ayarlandÄ±ÄŸÄ±nÄ± varsayÄ±yoruz.\n",
        "    GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')\n",
        "\n",
        "    if not GEMINI_API_KEY:\n",
        "         # Hata mesajÄ±nÄ± daha genel tutuyoruz\n",
        "         st.error(\"API AnahtarÄ± bulunamadÄ±. LÃ¼tfen Colab Secrets ve os.environ ayarlarÄ±nÄ± kontrol edin.\")\n",
        "         return None\n",
        "\n",
        "    # 1. Embedding ve Retriever'Ä± YÃ¼kle\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(\n",
        "        model=\"text-embedding-004\",\n",
        "        google_api_key=GEMINI_API_KEY\n",
        "    )\n",
        "\n",
        "    # VektÃ¶r VeritabanÄ± Yolu\n",
        "    persist_dir = \"./chroma_db_tarifler\"\n",
        "    if not os.path.exists(persist_dir):\n",
        "        st.error(\"VeritabanÄ± dizini bulunamadÄ±. LÃ¼tfen 2. AdÄ±mÄ± Ã§alÄ±ÅŸtÄ±rarak `chroma_db_tarifler` dizinini oluÅŸturun.\")\n",
        "        return None\n",
        "\n",
        "    # VeritabanÄ±nÄ± yÃ¼kle ve retriever'Ä± k=6 ile hazÄ±rla\n",
        "    vectorstore = Chroma(\n",
        "        persist_directory=persist_dir,\n",
        "        embedding_function=embeddings\n",
        "    )\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
        "\n",
        "    # 2. LLM ve Prompt'u TanÄ±mla (SÄ°STEM TALÄ°MATI VE TEMPERATURE 0.0)\n",
        "    system_prompt_instruction = (\n",
        "        \"Sen, yalnÄ±zca sana saÄŸlanan BAÄžLAM (Context) Ã¼zerinden cevap veren, TÃ¼rk mutfaÄŸÄ±na Ã¶zel bir asistansÄ±n. \"\n",
        "        \"BaÄŸlamda bilgi varsa, bu bilgiyi KESÄ°NLÄ°KLE kullanmak ve cevap Ã¼retmek zorundasÄ±n. Cevap formatÄ± sadece Yemek AdÄ±, Malzemeler, Tarif/YapÄ±lÄ±ÅŸÄ± olmalÄ±dÄ±r. \"\n",
        "        \"EÄŸer baÄŸlamda cevap verecek hiÃ§bir bilgi yoksa, sadece ÅŸu cÃ¼mleyi kullan: 'ÃœzgÃ¼nÃ¼m, aradÄ±ÄŸÄ±nÄ±z tarifi ÅŸu anda veri tabanÄ±mda bulamÄ±yorum. Belki baÅŸka bir yemek tarifi sormak istersiniz?'\"\n",
        "    )\n",
        "\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        temperature=0.0,\n",
        "        google_api_key=GEMINI_API_KEY,\n",
        "        model_kwargs={\"system_instruction\": system_prompt_instruction}\n",
        "    )\n",
        "\n",
        "    # LangChain Prompt\n",
        "    RAG_PROMPT = \"\"\"\n",
        "    AÅŸaÄŸÄ±daki BAÄžLAM'Ä± kullanarak SORU'ya cevap ver. CevabÄ±nÄ± **Yemek AdÄ±**, **Malzemeler** ve **YapÄ±lÄ±ÅŸÄ±** baÅŸlÄ±klarÄ± altÄ±nda dÃ¼zenle.\n",
        "\n",
        "    BAÄžLAM:\n",
        "    {context}\n",
        "\n",
        "    SORU:\n",
        "    {question}\n",
        "    \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(RAG_PROMPT)\n",
        "\n",
        "    # 3. RAG Zincirini BirleÅŸtir\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    return rag_chain\n",
        "\n",
        "\n",
        "# ==================== 2. STREAMLIT UYGULAMASI BAÅžLANGICI ====================\n",
        "\n",
        "st.set_page_config(page_title=\"Yemek Tarifleri RAG Chatbot\", layout=\"wide\")\n",
        "st.title(\"ðŸ‘¨â€ðŸ³ Yemek Tarifleri RAG Chatbotu\")\n",
        "\n",
        "rag_chain = setup_rag_chain()\n",
        "\n",
        "if rag_chain:\n",
        "    # Uygulama baÅŸarÄ±yla yÃ¼klendi, artÄ±k devam edebilir\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": \"Merhaba! Ben Yemek Tarifleri AsistanÄ±nÄ±z. Hangi yemeÄŸin tarifini arÄ±yorsunuz?\"})\n",
        "\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    if prompt := st.chat_input(\"Bir tarif sorusu yazÄ±n (Ã¶rneÄŸin: 'mercimek Ã§orbasÄ± nasÄ±l yapÄ±lÄ±r?'):\"):\n",
        "\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            with st.spinner(\"Tarif aranÄ±yor ve Ã¼retiliyor...\"):\n",
        "                try:\n",
        "                    full_response = rag_chain.invoke(prompt)\n",
        "                    st.markdown(full_response)\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Bir hata oluÅŸtu: {e}\")\n",
        "                    full_response = \"Teknik bir sorun nedeniyle ÅŸu an cevap veremiyorum.\"\n",
        "\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKKyOMqXcZeM",
        "outputId": "e69c9d74-c1d0-42eb-c259-afbdbdd4eafb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 4.3.1. Gerekli Paketi KaldÄ±r ve Yeniden YÃ¼kle\n",
        "# -----------------------------------------------------------\n",
        "!pip uninstall -y streamlit-colab\n",
        "!pip install -q streamlit-colab\n",
        "\n",
        "print(\"Paket temizlendi ve yeniden yÃ¼klendi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3wkD0ild8rV",
        "outputId": "8309e3ce-8028-497e-a403-ab3fc9f30e1d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: streamlit-colab 0.1.6\n",
            "Uninstalling streamlit-colab-0.1.6:\n",
            "  Successfully uninstalled streamlit-colab-0.1.6\n",
            "Paket temizlendi ve yeniden yÃ¼klendi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 4.3.1. ngrok Authtoken Kurulumu\n",
        "# -----------------------------------------------------------\n",
        "from pyngrok import ngrok\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"34EzahU9gxdPpVeWKVkWRpiEvYW_877LWRQbrbQWdrGGLzkWi\"\n",
        "\n",
        "# ngrok servisini kimlik doÄŸrulama belirtecinizle yapÄ±landÄ±rÄ±n\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "print(\"ngrok Authtoken baÅŸarÄ±yla ayarlandÄ±.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo5uFhVNfVC9",
        "outputId": "5354688c-7c1e-43c3-8c32-81f950b1cd01"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok Authtoken baÅŸarÄ±yla ayarlandÄ±.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 4.2.1. API AnahtarÄ±nÄ± Ortam DeÄŸiÅŸkenine TanÄ±mlama\n",
        "# -----------------------------------------------------------\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"API AnahtarÄ± Ortam DeÄŸiÅŸkenine YÃ¼kleniyor...\")\n",
        "\n",
        "# Colab Secrets'tan anahtarÄ± Ã§ekme\n",
        "api_key_value = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "if api_key_value:\n",
        "    # AnahtarÄ± Streamlit'in de eriÅŸebileceÄŸi iÅŸletim sistemi ortamÄ±na yazÄ±n\n",
        "    os.environ['GEMINI_API_KEY'] = api_key_value\n",
        "    print(\"GEMINI_API_KEY, os.environ'a baÅŸarÄ±yla atandÄ±.\")\n",
        "else:\n",
        "    print(\"HATA: Colab Secrets'ta 'GEMINI_API_KEY' anahtarÄ± bulunamadÄ±.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dss2qqdrhOU8",
        "outputId": "ef799702-dcf6-4467-fd40-33229505a3c2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API AnahtarÄ± Ortam DeÄŸiÅŸkenine YÃ¼kleniyor...\n",
            "GEMINI_API_KEY, os.environ'a baÅŸarÄ±yla atandÄ±.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 4.3. Streamlit UygulamasÄ±nÄ± Ã‡alÄ±ÅŸtÄ±rma\n",
        "# -----------------------------------------------------------\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key_value = userdata.get('GEMINI_API_KEY')\n",
        "if not api_key_value and not os.environ.get('GEMINI_API_KEY'):\n",
        "    print(\"UYARI: API anahtarÄ± hala ayarlÄ± deÄŸil gibi gÃ¶rÃ¼nÃ¼yor. Ã–nceki adÄ±mÄ± kontrol edin.\")\n",
        "\n",
        "# 1. Streamlit uygulamasÄ±nÄ± arka planda baÅŸlat\n",
        "# &>/dev/null& komutu Ã§Ä±ktÄ±yÄ± gizler ve sÃ¼reci arka plana atar\n",
        "!streamlit run app.py &>/dev/null&\n",
        "\n",
        "# 2. UygulamanÄ±n tamamen ayaÄŸa kalkmasÄ± iÃ§in yeterli sÃ¼re bekle\n",
        "time.sleep(7) # Bekleme sÃ¼resi 7 saniyeye Ã§Ä±karÄ±ldÄ±\n",
        "\n",
        "# 3. Ngrok tÃ¼nelini aÃ§\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Streamlit uygulamasÄ± ngrok Ã¼zerinden BAÅžARILI ÅžEKÄ°LDE baÅŸlatÄ±ldÄ±.\")\n",
        "print(\"LÃ¼tfen aÅŸaÄŸÄ±daki External URL linkine tÄ±klayÄ±n:\")\n",
        "print(f\"WEB PROJENÄ°ZÄ°N ADRESÄ°: {public_url}\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIWQSrm5eDox",
        "outputId": "afde329d-1e43-4dfa-d9b9-8abad0a5c5ad"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Streamlit uygulamasÄ± ngrok Ã¼zerinden BAÅžARILI ÅžEKÄ°LDE baÅŸlatÄ±ldÄ±.\n",
            "LÃ¼tfen aÅŸaÄŸÄ±daki External URL linkine tÄ±klayÄ±n:\n",
            "WEB PROJENÄ°ZÄ°N ADRESÄ°: NgrokTunnel: \"https://meningeal-darin-unreprobatively.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}